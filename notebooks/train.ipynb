{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a4edf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics import JaccardIndex\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "from hydra import initialize, compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2668df41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the project root directory to the Python path\n",
    "cur_dir     = Path.cwd()\n",
    "project_dir = cur_dir.parent\n",
    "sys.path.append(str(project_dir))\n",
    "\n",
    "from models.DinoFPNbn import DinoFPN as DinoSeg\n",
    "from models.tools import CombinedLoss\n",
    "from data.dataset import KittiSemSegDataset\n",
    "from utils.others import save_checkpoint, load_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a129038f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Achieves 85% mIoU on KITTI-360 validation set after ~3 epochs.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dd7eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8296f390",
   "metadata": {},
   "outputs": [],
   "source": [
    "with initialize(version_base=None, config_path=f\"../configs\", job_name=\"train_and_log\"):\n",
    "    cfg = compose(config_name=\"config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cc52bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_size = (cfg.augmentation.crop_height, cfg.augmentation.crop_width)\n",
    "train_transform = A.Compose([\n",
    "    # -- Geometric --\n",
    "    A.RandomCrop(height=crop_size[0], width=crop_size[1], p=1.0), # preserve scale/context\n",
    "    A.Affine(\n",
    "        # translate_percent={\"x\": (-0.05, 0.05), \"y\": (-0.05, 0.05)}, # ±5% shift\n",
    "        scale=(0.8, 1.0),                                           # zoom between 0.8×–1.0×\n",
    "        rotate=(-3, 3),                                             # ±3° roll\n",
    "        interpolation=cv2.INTER_LINEAR,\n",
    "        mask_interpolation=cv2.INTER_NEAREST,\n",
    "        border_mode=cv2.BORDER_CONSTANT,\n",
    "        fill=255,\n",
    "        fill_mask=255,\n",
    "        p=0.7\n",
    "    ),\n",
    "    A.Perspective(scale=(0.01, 0.03), p=0.5),  # tiny camera viewpoint warp\n",
    "\n",
    "    # -- Photometric --\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.15, contrast_limit=0.15, p=0.5),\n",
    "    A.RandomGamma(gamma_limit=(90, 110), p=0.5),\n",
    "    A.OneOf([\n",
    "        A.RandomFog(fog_coef_range=(0.05, 0.2), p=1.0),\n",
    "        A.RandomShadow(shadow_roi=(0, 0.5, 1, 1), num_shadows_limit=(1, 2), p=1.0),\n",
    "        A.RandomSunFlare(src_radius=50, p=1.0)\n",
    "    ], p=0.5),\n",
    "\n",
    "    # -- Occlusions --\n",
    "    A.CoarseDropout(num_holes_range=(1, 4), \n",
    "                    hole_height_range=(5, 30), \n",
    "                    hole_width_range=(5, 30), \n",
    "                    p=0.5),                                # random occlusion\n",
    "\n",
    "    # — Blur & noise: motion, sensor, compression —\n",
    "    A.OneOf([\n",
    "        A.MotionBlur(blur_limit=5, p=0.4),\n",
    "        A.GaussianBlur(blur_limit=(3,5), p=0.3),\n",
    "        A.MedianBlur(blur_limit=3, p=0.2),\n",
    "    ], p=0.5),\n",
    "    A.GaussNoise(\n",
    "        std_range=(10.0/255.0, 50.0/255.0),\n",
    "        mean_range=(0.0, 0.0),\n",
    "        p=0.5\n",
    "    )\n",
    "])\n",
    "\n",
    "# Define deterministic transforms for validation\n",
    "val_transform = A.Compose([\n",
    "    A.CenterCrop(height=crop_size[0], width=crop_size[1])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485ebf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset and DataLoader\n",
    "dataset_root = '/home/panos/Documents/data/kitti-360'\n",
    "train_dataset = KittiSemSegDataset(dataset_root, train=True, transform=train_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=cfg.train.batch_size, \n",
    "                            shuffle=True, num_workers=cfg.dataset.num_workers, pin_memory=True)\n",
    "val_dataset = KittiSemSegDataset(dataset_root, train=False, transform=val_transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=cfg.train.batch_size,\n",
    "                        shuffle=False, num_workers=cfg.dataset.num_workers, pin_memory=True)\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset size: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018284aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model, loss function, and optimizer\n",
    "model = DinoSeg(\n",
    "    num_labels=cfg.dataset.num_classes,\n",
    "    model_cfg=cfg.model\n",
    ")\n",
    "model = model.to(device)\n",
    "criterion = CombinedLoss(alpha=0.8, ignore_index=255)\n",
    "optimizer = optim.Adam(model.parameters(), lr=cfg.train.learning_rate)\n",
    "\n",
    "# Metric: mean IoU over all classes\n",
    "miou_metric = JaccardIndex(\n",
    "    task='multiclass',\n",
    "    num_classes=cfg.dataset.num_classes,\n",
    "    average='micro',\n",
    "    ignore_index=255\n",
    ").to(device)\n",
    "\n",
    "# Initialize learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=cfg.train.num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57adae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model if it exists\n",
    "start_epoch, berst_val_miou = load_checkpoint(model, optimizer, cfg.checkpoint, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e330e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for epoch in range(start_epoch, cfg.train.num_epochs + 1):\n",
    "    ####### TRAINING #######\n",
    "    model.train()\n",
    "    miou_metric.reset()\n",
    "    running_train_loss = 0.0\n",
    "\n",
    "    # Iterate over the training dataset\n",
    "    train_bar = tqdm(train_loader, desc=f\"[Epoch {epoch}] Train\")\n",
    "    for batch_idx, (imgs, masks) in enumerate(train_bar, start=1):\n",
    "        imgs = imgs.permute(0, 3, 1, 2)  # [B, H, W, C] -> [B, C, H, W]\n",
    "        input = model.process(imgs).to(device)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward\n",
    "        logits = model(input)\n",
    "\n",
    "        # loss\n",
    "        masks = masks.to(device)  # [B, H, W]\n",
    "        loss = criterion(logits, masks.long())\n",
    "\n",
    "        # scale the loss down so that gradients accumulate correctly\n",
    "        loss = loss / cfg.train.accum_steps\n",
    "\n",
    "        # compute IoU\n",
    "        preds = torch.argmax(logits, dim=1)  # [B, H, W]\n",
    "        miou_metric.update(preds, masks)\n",
    "\n",
    "        # Compute gradients and step the optimizer\n",
    "        loss.backward()\n",
    "\n",
    "        # every accum_steps, step & zero_grad\n",
    "        if batch_idx % cfg.train.accum_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        # accumulate losses\n",
    "        running_train_loss += loss.item()\n",
    "        train_bar.set_postfix(loss=running_train_loss / batch_idx)\n",
    "\n",
    "    avg_train_loss = running_train_loss / len(train_loader)\n",
    "    avg_train_miou = miou_metric.compute().item()\n",
    "\n",
    "    ####### VALIDATION #######\n",
    "    model.eval()\n",
    "    running_val_loss = 0.0\n",
    "    miou_metric.reset()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        val_bar = tqdm(val_loader, desc=f\"[Epoch {epoch}/{cfg.train.num_epochs}]  Val\")\n",
    "        for batch_idx, (imgs, masks) in enumerate(val_bar, start=1):\n",
    "            imgs = imgs.permute(0, 3, 1, 2)  # [B, H, W, C] -> [B, C, H, W]\n",
    "            input = model.process(imgs).to(device)\n",
    "\n",
    "            # forward + loss\n",
    "            logits = model(input)\n",
    "            cls_map = None\n",
    "\n",
    "            # Loss\n",
    "            masks = masks.to(device)  # [B, H, W]\n",
    "            loss = criterion(logits, masks.long())\n",
    "\n",
    "            # accumulate losses\n",
    "            running_val_loss += loss.item()\n",
    "\n",
    "            # compute IoU on this batch\n",
    "            preds = torch.argmax(logits, dim=1)  # [B, H, W]\n",
    "            miou_metric.update(preds, masks)\n",
    "\n",
    "            val_bar.set_postfix(val_loss=running_val_loss / batch_idx)\n",
    "\n",
    "    avg_val_loss = running_val_loss / len(val_loader)\n",
    "    avg_val_miou = miou_metric.compute().item()\n",
    "\n",
    "    # Update learning rate based on validation loss\n",
    "    scheduler.step()\n",
    "\n",
    "    ####### PRINT & CHECKPOINT #######\n",
    "    print(\n",
    "        f\"Epoch {epoch:02d} | Learning Rate: {optimizer.param_groups[0]['lr']:.6f} | \"\n",
    "        f\"\\n  Train Loss: {avg_train_loss:.4f} | mIoU: {avg_train_miou:.4f} \"\n",
    "        f\"\\n  Val   Loss: {avg_val_loss:.4f} | mIoU: {avg_val_miou:.4f}\"\n",
    "    )\n",
    "\n",
    "    # Save best model\n",
    "    if avg_val_miou > best_val_miou:\n",
    "        best_val_miou = avg_val_miou\n",
    "        save_checkpoint(model, optimizer, epoch, best_val_miou, cfg.checkpoint, scheduler)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
